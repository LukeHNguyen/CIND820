{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Read data from file \n",
    "file_path = r'D:\\00. MSc Data Analytic\\CIND820\\Data\\Crop data\\Final_Data.xlsx'\n",
    "weather_df = pd.read_excel(file_path, sheet_name='Weather')\n",
    "crop_df = pd.read_excel(file_path, sheet_name='Crop')\n",
    "\n",
    "cols = ['Year', 'County', 'Station Name', 'Climate ID', 'Date/Time', 'Month', 'Day', 'Max Temp (°C)', 'Min Temp (°C)',\n",
    "        'Mean Temp (°C)', 'Heat Deg Days (°C)', 'Cool Deg Days (°C)', 'Total Rain (mm)', 'Total Snow (cm)',\n",
    "        'Total Precip (mm)', 'Snow on Grnd (cm)', 'Dir of Max Gust (1s deg)', 'Spd of Max Gust (km/h)',\n",
    "        'Max Temp Flag', 'Min Temp Flag', 'Mean Temp Flag', 'Heat Deg Days Flag', 'Cool Deg Days Flag',\n",
    "        'Total Rain Flag', 'Total Snow Flag', 'Total Precip Flag', 'Snow on Grnd Flag', 'Dir of Max Gust Flag',\n",
    "        'Spd of Max Gust Flag']\n",
    "subset_df = weather_df[cols]\n",
    "\n",
    "# Perform one-hot encoding on the categorical variables in Weather dataset:\n",
    "for col in ['Max Temp Flag', 'Min Temp Flag', 'Mean Temp Flag', 'Heat Deg Days Flag', 'Cool Deg Days Flag']:\n",
    "    onehot_df = pd.get_dummies(subset_df[col], prefix=col)\n",
    "    subset_df = pd.concat([subset_df, onehot_df], axis=1)\n",
    "    subset_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "for col in ['Total Rain Flag', 'Total Snow Flag', 'Total Precip Flag', 'Snow on Grnd Flag', 'Dir of Max Gust Flag',\n",
    "            'Spd of Max Gust Flag']:\n",
    "    onehot_df = pd.get_dummies(subset_df[col], prefix=col)\n",
    "    subset_df = pd.concat([subset_df, onehot_df], axis=1)\n",
    "    subset_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "subset_df = subset_df.drop(['Station Name', 'Climate ID','Date/Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lupin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\impute\\_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Drop the attribute columns with full data\n",
    "subset_df.drop(['Year', 'County', 'Month', 'Day'], axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values using regression imputation\n",
    "imputer = IterativeImputer(random_state=0, max_iter=100)\n",
    "imputed_df = pd.DataFrame(imputer.fit_transform(subset_df), columns=subset_df.columns)\n",
    "\n",
    "# Combine the attribute columns and imputed columns into a single dataframe\n",
    "output_df = pd.concat([weather_df[['Year', 'County', 'Month', 'Day']], imputed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by County and Year and aggregate the data\n",
    "grouped_df = output_df.groupby(['County', 'Year']).agg({\n",
    "    'Max Temp (°C)': ['mean', 'max', 'min', 'std'],\n",
    "    'Min Temp (°C)': ['mean', 'max', 'min', 'std'],\n",
    "    'Mean Temp (°C)': ['mean', 'max', 'min', 'std'],\n",
    "    'Heat Deg Days (°C)': ['mean', 'max', 'min', 'std'],\n",
    "    'Cool Deg Days (°C)': ['mean', 'max', 'min', 'std'],\n",
    "    'Total Rain (mm)': ['mean', 'max', 'min', 'std'],\n",
    "    'Total Snow (cm)': ['mean', 'max', 'min', 'std'],\n",
    "    'Total Precip (mm)': ['mean', 'max', 'min', 'std'],\n",
    "    'Snow on Grnd (cm)': ['mean', 'max', 'min', 'std'],\n",
    "    'Dir of Max Gust (1s deg)': ['mean', 'max', 'min', 'std'],\n",
    "    'Spd of Max Gust (km/h)': ['mean', 'max', 'min', 'std'],\n",
    "    'Max Temp Flag_E': 'sum',\n",
    "    'Max Temp Flag_M': 'sum',\n",
    "    'Min Temp Flag_E': 'sum',\n",
    "    'Min Temp Flag_M': 'sum',\n",
    "    'Mean Temp Flag_E': 'sum',    \n",
    "    'Mean Temp Flag_M': 'sum',\n",
    "    'Heat Deg Days Flag_E': 'sum',\n",
    "    'Heat Deg Days Flag_M': 'sum',\n",
    "    'Cool Deg Days Flag_E': 'sum',\n",
    "    'Cool Deg Days Flag_M': 'sum',\n",
    "    'Total Rain Flag_A': 'sum',\n",
    "    'Total Rain Flag_C': 'sum',\n",
    "    'Total Rain Flag_E': 'sum',\n",
    "    'Total Rain Flag_F': 'sum',\n",
    "    'Total Rain Flag_L': 'sum',\n",
    "    'Total Rain Flag_M': 'sum',\n",
    "    'Total Rain Flag_T': 'sum',\n",
    "    'Total Snow Flag_A': 'sum',\n",
    "    'Total Snow Flag_C': 'sum',\n",
    "    'Total Snow Flag_E': 'sum',\n",
    "    'Total Snow Flag_F': 'sum',\n",
    "    'Total Snow Flag_M': 'sum',\n",
    "    'Total Snow Flag_T': 'sum',\n",
    "    'Total Precip Flag_A': 'sum',\n",
    "    'Total Precip Flag_C': 'sum',\n",
    "    'Total Precip Flag_E': 'sum',\n",
    "    'Total Precip Flag_F': 'sum',\n",
    "    'Total Precip Flag_M': 'sum',\n",
    "    'Total Precip Flag_T': 'sum',\n",
    "    'Snow on Grnd Flag_E': 'sum',\n",
    "    'Snow on Grnd Flag_M': 'sum',\n",
    "    'Snow on Grnd Flag_T': 'sum',\n",
    "    'Dir of Max Gust Flag_E': 'sum',\n",
    "    'Dir of Max Gust Flag_M': 'sum',\n",
    "    'Spd of Max Gust Flag_E': 'sum',\n",
    "    'Spd of Max Gust Flag_M': 'sum'\n",
    "})\n",
    "\n",
    "# Flatten the resulting column names by joining the multi-index columns\n",
    "grouped_df.columns = ['_'.join(col).strip() for col in grouped_df.columns.values]\n",
    "grouped_df = grouped_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the \"County\" and \"Year\" columns, then clear all record with no Production\n",
    "merged_df = pd.merge(grouped_df, crop_df, on=[\"County\", \"Year\"])\n",
    "merged_df[\"Yield (kg/Acres seeded)\"] = merged_df.apply(lambda row: (row[\"Sum of Production ('000 tonnes)\"] * 1000) / row[\"Sum of Acres seeded\"] if row[\"Sum of Acres seeded\"] != 0 else 0, axis=1)\n",
    "merged_df = merged_df.drop(merged_df[merged_df[\"Yield (kg/Acres seeded)\"] == 0].index)\n",
    "merged_df = merged_df.drop([\"Sum of Production ('000 tonnes)\", \"Sum of Acres seeded\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 34214.95047265146\n",
      "SVM MSE: 27029.863705540407\n"
     ]
    }
   ],
   "source": [
    "#remove County, Product and Year from data\n",
    "merged_df = merged_df.drop([\"County\",\"Year\",\"Product\"], axis=1)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y) and define which models use\n",
    "X = merged_df.drop(['Yield (kg/Acres seeded)'], axis=1)\n",
    "y = merged_df['Yield (kg/Acres seeded)']\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "svr_regressor = SVR(kernel='rbf')\n",
    "\n",
    "# Define the cross-validation method\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate the Decision Tree model\n",
    "dt_scores = cross_val_score(dt_regressor, X, y, scoring='neg_mean_squared_error', cv=kfold)\n",
    "dt_mse = -dt_scores.mean()\n",
    "\n",
    "# Train and evaluate the Support Vector Machines model\n",
    "svr_scores = cross_val_score(svr_regressor, X, y, scoring='neg_mean_squared_error', cv=kfold)\n",
    "svr_mse = -svr_scores.mean()\n",
    "\n",
    "#print out initial results\n",
    "print('Decision Tree MSE:', dt_mse)\n",
    "print('SVM MSE:', svr_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
